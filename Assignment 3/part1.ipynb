{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f85271f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c3ba473",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"emails.csv\").to_numpy()\n",
    "corpus = data[:,0]\n",
    "y = data[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81248ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer = \"word\", ngram_range = (1,1)) # only consider unigrams\n",
    "X = vectorizer.fit_transform(corpus).toarray()\n",
    "X = np.squeeze(np.asarray(X))\n",
    "N, M = X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "742ca66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are total of 1368 spam and 4360 ham mails\n",
      "(1368, 37303) (4360, 37303)\n"
     ]
    }
   ],
   "source": [
    "freq_words = np.zeros((M, 2))\n",
    "spam_idx, ham_idx = y == 1, y == 0\n",
    "\n",
    "print(\"There are total of %d spam and %d ham mails\" % (X[spam_idx].shape[0], X[ham_idx].shape[0]))\n",
    "print(X[spam_idx].shape, X[ham_idx].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d965b741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words only seen in spam mails: 10229\n",
      "Number of words only seen in ham mails: 18529\n"
     ]
    }
   ],
   "source": [
    "spam_num, ham_num = X[spam_idx].sum(axis=0), X[ham_idx].sum(axis=0)\n",
    "freq_words[:,0] += spam_num\n",
    "freq_words[:,1] += ham_num\n",
    "\n",
    "print(\"Number of words only seen in spam mails:\", np.sum(freq_words[:,1] == 0))\n",
    "print(\"Number of words only seen in ham mails:\", np.sum(freq_words[:,0] == 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9817e3d",
   "metadata": {},
   "source": [
    "Some statistics about the data:\n",
    "1. There are total of **37303** distinct words in the dataset and **5728** lines of mails.\n",
    "2. In these words, **10229** of them is seen only in spam mails and **18529** of them is seen only in ham mails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8d8f873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Words with highest R_s ####\n",
      "Word\tR_s\tN_s\tN\n",
      "projecthoneypot\t1.00\t110.0\t110\n",
      "viagra\t1.00\t174.0\t174\n",
      "stationery\t1.00\t120.0\t120\n",
      "2005\t0.99\t374.0\t379\n",
      "engines\t0.97\t112.0\t115\n",
      "advertisement\t0.97\t102.0\t105\n",
      "adobe\t0.97\t462.0\t476\n",
      "jul\t0.96\t162.0\t168\n",
      "2004\t0.95\t169.0\t177\n",
      "grants\t0.95\t110.0\t116\n",
      "#### Words with highest R_h ####\n",
      "Word\tR_h\tN_h\tN\n",
      "na\t0.99\t616.0\t623\n",
      "model\t0.99\t1287.0\t1306\n",
      "attached\t0.98\t898.0\t912\n",
      "schedule\t0.98\t637.0\t647\n",
      "option\t0.98\t561.0\t570\n",
      "london\t0.98\t828.0\t843\n",
      "09\t0.98\t1085.0\t1105\n",
      "john\t0.98\t1016.0\t1035\n",
      "summer\t0.98\t617.0\t629\n",
      "08\t0.98\t1192.0\t1216\n"
     ]
    }
   ],
   "source": [
    "ratios_s = freq_words[:,0] / X.sum(axis=0) # total times in spam / total usage of the word\n",
    "ratios_h = freq_words[:,1] / X.sum(axis=0) # total times in ham / total usage of the word\n",
    "idx_s_rats = np.argsort(ratios_s)[::-1]\n",
    "idx_h_rats = np.argsort(ratios_h)[::-1]\n",
    "words = vectorizer.get_feature_names_out()\n",
    "\n",
    "\n",
    "print(\"#### Words with highest R_s ####\")\n",
    "count = 0\n",
    "print(\"Word\",\"R_s\",\"N_s\",\"N\", sep=\"\\t\")\n",
    "for i in idx_s_rats:\n",
    "    if X[:,i].sum() > 100:       \n",
    "        print(words[i], \"%.2f\" % ratios_s[i], freq_words[i,0], X[:,i].sum(), sep='\\t')\n",
    "        count += 1\n",
    "        if count == 10:\n",
    "            break\n",
    "\n",
    "print(\"#### Words with highest R_h ####\")\n",
    "count = 0\n",
    "print(\"Word\",\"R_h\",\"N_h\",\"N\", sep=\"\\t\")\n",
    "for i in idx_h_rats:\n",
    "    if ratios_h[i] < 0.99 and X[:,i].sum() > 500:       \n",
    "        print(words[i], \"%.2f\" % ratios_h[i], freq_words[i,1], X[:,i].sum(), sep='\\t')\n",
    "        count += 1\n",
    "        if count == 10:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53af7f0",
   "metadata": {},
   "source": [
    "We compare the words according to their spam ratio which is defined as follows:<br>\n",
    "<br>\n",
    "$$\\large R_s = N_s / N,\\ R_h = N_h / N $$<br>\n",
    "where:\n",
    "- $N_s$ number of occurances in a spam mail of the word.\n",
    "- $N_h$ number of occurances in a ham mail of the word\n",
    "- $N$ is the total occurances.<br>\n",
    "\n",
    "In the upper cell, we print the 10 words with highest $R_s$ and $N > 100$, highest $R_h$ and $N > 500$. We selected the 3 words among them and inspect their statistics:\n",
    "1. **viagra**: We see that in this dataset all the mails that includes \"viagra\" are **spam**, since $R_s = 1.0$. Even though the $N$ is quite small (174), from prior experience we know that these type of mails are usually spam.\n",
    "2. **adobe**: We see that in this dataset most of the mails that includes \"adobe\" are spam, with $R_s = 0.97$. Furthermore because $N = 476$ and $N_s = 462$ (which are quite high occurances), we can conclude that this word provides a useful distinction between two type of mails.\n",
    "3. **schedule**: We see that in this dataset mos of the mails that includes \"schedule\" are ham, with $R_h = 0.98$. We know that from prior experience that mails that mentions schedule are usually not spam.\n",
    "\n",
    "We can conclude that it is feasible to label mails as spam or ham by looking at the words. However there are few drawbacks in this dataset:\n",
    "1. Even though some of the words has high $R_s$ their $N$ is quite low (< 100). This will result in a **biased prediction**.\n",
    "2. There are some words that are only numbers (09, 08, 2005, 2004) which shouldn't be telling a much about the type of the mail. However because of the dataset, some of these words has high $R_s$ and $R_h$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
