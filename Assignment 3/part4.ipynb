{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3318cc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "MODES = {\n",
    "    \"unigram\" : (1, 1),\n",
    "    \"bigram\" : (2, 2),\n",
    "    \"uni-bigram\" : (1, 2)\n",
    "}\n",
    "\n",
    "\n",
    "class NaiveBayes:\n",
    "    def __init__(self, mode: str = \"unigram\", stop_words = None) -> None:\n",
    "        \"\"\"\n",
    "        Initialize NaiveBayes model\n",
    "\n",
    "        Args:\n",
    "            mode (str, optional): Mode for BagOfWords, should be either Unigram or Bigram. Defaults to \"unigram\".\n",
    "            stop_words (list, optional): Stop words to eliminate from BagOfWords\n",
    "        \"\"\"\n",
    "        self.count_vector = None\n",
    "        self.probability_dict = dict()\n",
    "\n",
    "        assert mode in MODES.keys(), \"Mode should be either bigram or unigram\"\n",
    "        self.ngram_mode = MODES[mode]\n",
    "        self.stop_words = stop_words\n",
    "\n",
    "    def fit(self, x: np.ndarray, y: np.ndarray) -> None:\n",
    "        \"\"\"\n",
    "        Fit the data, calculate probabilities according to it\n",
    "\n",
    "        Args:\n",
    "            x (np.ndarray): data with shape (N,1), each row consists of a mail\n",
    "            y (np.ndarray): data with shape (N,), each row consists of the label of the mail (0 for ham, 1 for spam)\n",
    "        \"\"\"\n",
    "\n",
    "        # columns is list of every words without their counts, counts stores in count_vector\n",
    "        self.count_vector, columns = self.__vectorizer(x)\n",
    "\n",
    "        self.__calculate_class_prior(y)     # calculates P(spam) and P (ham), and adds them into probability_dict\n",
    "        # calculates P(x(i)|spam) and P(x(i)|ham) values, and adds them into probability_dict\n",
    "        self.__calculate_likelihoods(y, columns, 1)\n",
    "\n",
    "    def predict(self, x_predict: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Predict the labels of the mails in x_predict\n",
    "\n",
    "        Args:\n",
    "            x_predict (np.ndarray): Data to be predicted, shape (N,1)\n",
    "\n",
    "        Returns:\n",
    "            y_predict (np.ndarray): Predictions for the mails, shape (N,)\n",
    "        \"\"\"\n",
    "\n",
    "        n = x_predict.shape[0]\n",
    "        y_predict = np.zeros(n)\n",
    "\n",
    "        vector, columns = self.__vectorizer(x_predict)\n",
    "\n",
    "        for i in range(n):\n",
    "            probability_of_spam = 0\n",
    "            probability_of_ham = 0\n",
    "\n",
    "            word_idx = np.arange(columns.shape[0])[vector[i] > 0] # only work on words that the text has\n",
    "            # calculate P(vj | text)\n",
    "            for j in word_idx:\n",
    "                if \"%s|spam\" % columns[j] in self.probability_dict.keys():\n",
    "                    probability_of_spam += vector[i][j] * self.probability_dict[columns[j] + \"|spam\"]\n",
    "                    probability_of_ham += vector[i][j] * self.probability_dict[columns[j] + \"|ham\"]\n",
    "\n",
    "            probability_of_spam += self.probability_dict[\"spam\"]\n",
    "            probability_of_ham += self.probability_dict[\"ham\"]\n",
    "\n",
    "            y_predict[i] = 1 if probability_of_spam > probability_of_ham else 0\n",
    "\n",
    "        return y_predict\n",
    "\n",
    "    def __vectorizer(self, arr: np.ndarray) -> tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Creates a matrix which stores the words that emails includes and their counts in each email\n",
    "\n",
    "        :param arr: an numpy array with shape (N,1) for\n",
    "        :return: a CountVectorizer matrix (N, number of different words in emails) and a vector named columns\n",
    "        with shape (number of different words in emails,1) which stores all words appears in mails\n",
    "        \"\"\"\n",
    "\n",
    "        # initializes CountVectorizer item with ngram_mode\n",
    "        vectorizer = CountVectorizer(ngram_range=self.ngram_mode, stop_words=self.stop_words)\n",
    "\n",
    "        # vector that holds all words in emails and their counts for each item\n",
    "        vector = vectorizer.fit_transform(arr)\n",
    "\n",
    "        # convert vector variable to array for usability\n",
    "        count_vector = vector.toarray()\n",
    "\n",
    "        # names of columns\n",
    "        columns = vectorizer.get_feature_names_out()\n",
    "\n",
    "        return count_vector, columns\n",
    "\n",
    "    def __calculate_class_prior(self, y: np.ndarray) -> None:\n",
    "        \"\"\"\n",
    "        Calculates class probabilities [P(spam) and P(ham)] for training examples, and adds the result into\n",
    "        self.probability dictionary as \"spam\" and \"ham\" labels\n",
    "\n",
    "        :param y: data with shape (N,), each row consists of the label of the mail (0 for ham, 1 for spam)\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "\n",
    "        # labels are only 0 and 1 therefore if we sum all items we get number of 1s\n",
    "        # instead of a for loop we can use this method\n",
    "        number_of_spam = np.sum(y)\n",
    "        number_of_ham = len(y) - number_of_spam\n",
    "\n",
    "        self.probability_dict[\"spam\"] = np.log(number_of_spam / y.shape[0])  # P(spam) = number of spams / N\n",
    "        self.probability_dict[\"ham\"] = np.log(number_of_ham / y.shape[0])     # P(ham) = number of hams / N\n",
    "\n",
    "    def __calculate_likelihoods(self, y: np.ndarray, columns: np.ndarray, alpha: int) -> None:\n",
    "        \"\"\"\n",
    "        Calculates likelihoods of each word that contains in emails as P(word|spam) and P(word|ham), and adds the results\n",
    "        into self.probability dictionary as \"word|spam\" and \"word|ham\" labels\n",
    "\n",
    "        :param y: data with shape (N,), each row consists of the label of the mail (0 for ham, 1 for spam)\n",
    "        :param columns: a vector with shape (number of different words in emails,1) which stores all words appears in mails\n",
    "        :param alpha: int value for smoothing\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "\n",
    "        N, D = self.count_vector.shape\n",
    "        spam_vector, ham_vector = np.sum(self.count_vector[y == 1], axis=0), np.sum(self.count_vector[y == 0], axis=0)\n",
    "\n",
    "        n_s = np.sum(spam_vector) # | Text_spam |\n",
    "        n_h = np.sum(ham_vector) # | Text_ham  |\n",
    "\n",
    "        for word_i in range(D):\n",
    "            n_w_s = spam_vector[word_i]\n",
    "            n_h_s = ham_vector[word_i]\n",
    "\n",
    "            self.probability_dict[\"%s|spam\" % columns[word_i]] = np.log((n_w_s + alpha) / (n_s + D))\n",
    "            self.probability_dict[\"%s|ham\" % columns[word_i]] = np.log((n_h_s + alpha) / (n_h + D))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53513068",
   "metadata": {},
   "source": [
    "## 4. Part 4 Calculation of Performance Metrics\n",
    "\n",
    "Below we calculate the wanted performance metrics for different settings of the model.\n",
    "\n",
    "$$\\textbf{Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN}$$\n",
    "$$\\textbf{Precision} = \\frac{TP}{TP + FP}$$\n",
    "$$\\textbf{Recall} = \\frac{TP}{TP + FN}$$\n",
    "$$\\textbf{F1 Score} = \\frac{2 * (Precision * Recall)}{Precision + Recall}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23bcdb8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance metrics with settings ngram=unigram, stop_words=True:\n",
      "---------------------------\n",
      "Accuracy:\t0.990401\n",
      "Precision:\t0.978182\n",
      "Recall:\t0.981752\n",
      "F1 Score:\t0.979964\n",
      "\n",
      "\n",
      "Performance metrics with settings ngram=bigram, stop_words=True:\n",
      "---------------------------\n",
      "Accuracy:\t0.990401\n",
      "Precision:\t0.992509\n",
      "Recall:\t0.967153\n",
      "F1 Score:\t0.979667\n",
      "\n",
      "\n",
      "Performance metrics with settings ngram=unigram, stop_words=False:\n",
      "---------------------------\n",
      "Accuracy:\t0.989529\n",
      "Precision:\t0.974638\n",
      "Recall:\t0.981752\n",
      "F1 Score:\t0.978182\n",
      "\n",
      "\n",
      "Performance metrics with settings ngram=bigram, stop_words=False:\n",
      "---------------------------\n",
      "Accuracy:\t0.990401\n",
      "Precision:\t0.996226\n",
      "Recall:\t0.963504\n",
      "F1 Score:\t0.979592\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "file_path = os.path.join(os.getcwd(), \"emails.csv\")\n",
    "df = pd.read_csv(file_path)\n",
    "X, y = df[\"text\"].to_numpy(), df[\"spam\"].to_numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=29, stratify=y\n",
    ")\n",
    "\n",
    "args = [(\"unigram\", ENGLISH_STOP_WORDS), (\"bigram\", ENGLISH_STOP_WORDS), (\"unigram\", None), (\"bigram\", None)]\n",
    "for arg in args:\n",
    "    model = NaiveBayes(*arg)        # initializes the model\n",
    "    model.fit(X_train, y_train)      # training\n",
    "    y_predict = model.predict(X_test)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_predict).ravel()\n",
    "    \n",
    "    acc = (tp + tn) / (tn + fp + fn + tp)\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1 = 2 * recall * precision / (recall + precision)\n",
    "    print(\"Performance metrics with settings ngram=%s, stop_words=%s:\" % (arg[0], arg[1] != None))\n",
    "    print(\"---------------------------\")\n",
    "    print(\"Accuracy:\\t%f\" % acc)\n",
    "    print(\"Precision:\\t%f\" % precision)\n",
    "    print(\"Recall:\\t%f\" % recall)\n",
    "    print(\"F1 Score:\\t%f\" % f1)\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
